{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMuRTyO168wyOqU4IgorEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/155193/DGTAL/blob/master/practice_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_kXC8WnpBJi",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IsmHyrg632R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "01e36e85-3897-47e9-9384-aa6be2504e11"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import optimizers\n",
        "#from tensorflow.keras import adam\n",
        "#tf.keras.optimizers.Adam\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.clear_session()\n",
        "data_entrenamiento=\"D:/data/entrenamiento\"\n",
        "data_validacion=\"D:/data/validacion\"\n",
        "\n",
        "#parametros\n",
        "epocas=20\n",
        "altura, longitud = 100, 100\n",
        "batch_size=32\n",
        "pasos=1000\n",
        "pasos_validacion=200\n",
        "filtrosConv1=32\n",
        "filtrosConv2=64\n",
        "tamano_filtro1=(3,3)\n",
        "tamano_filtro2=(2,2)\n",
        "tamano_pool=(2,2)\n",
        "clases=3\n",
        "lr=0.0005\n",
        "\n",
        "#preprocesamiento de imagenes\n",
        "entrenamiento_datagen=ImageDataGenerator(  \n",
        "    shear_range=0.3, \n",
        "    zoom_range=0.3, \n",
        "    horizontal_flip=True, \n",
        "    rescale=1./255\n",
        ")\n",
        "validacion_datagen=ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "imagen_entrenamiento=entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(altura,longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "imagen_validacion=validacion_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size=(altura,longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "#Red CNN\n",
        "cnn=Sequential()\n",
        "cnn.add(Convolution2D(filtrosConv1,tamano_filtro1,padding='same',input_shape=(altura,longitud,3),activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "cnn.add(Convolution2D(filtrosConv2,tamano_filtro2,padding='same',activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(256,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(clases,activation='softmax'))\n",
        "#model.compile(optimizer=tf.keras.optimizers.Blah() metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "#cnn.compile(loss='categorical_crossentropy' optimizer=optimizers.adam(lr=lr) metrics= 'accuracy' )\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(lr=lr),metrics=['accuracy'])\n",
        "cnn.fit(imagen_entrenamiento,steps_per_epoch=pasos,epochs=epocas,validation_data=imagen_validacion,validation_steps=pasos_validacion)\n",
        "dir=\"D:/modelo/\"\n",
        "cnn.save(\"D:/modelo/modelo.h5\")\n",
        "cnn.save_weights(\"D:/modelo/pesos.h5\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9ac3aea57630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltura\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlongitud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m imagen_validacion=validacion_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/data/entrenamiento'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axhvGAJu6W8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4dwAcZS6Xam",
        "colab_type": "text"
      },
      "source": [
        "#parametros\n",
        "epocas=20\n",
        "altura, longitud = 100, 100\n",
        "batch_size=32\n",
        "pasos=1000\n",
        "pasos_validacion=200\n",
        "filtrosConv1=32\n",
        "filtrosConv2=64\n",
        "tamano_filtro1=(3,3)\n",
        "tamano_filtro2=(2,2)\n",
        "tamano_pool=(2,2)\n",
        "clases=3\n",
        "lr=0.0005\n",
        "\n",
        "#preprocesamiento de imagenes\n",
        "entrenamineto_datagen=ImageDataGenerator(  \n",
        "    shear_range=0.3, \n",
        "    zoom_range=0.3, \n",
        "    horizontal_flip=True, \n",
        "    rescale=1./255\n",
        ")\n",
        "validacion_datagen=ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "imagen_entrenamiento=entrenamineto_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(altura,longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "imagen_validacion=validacion_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size=(altura,longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n"
      ]
    }
  ]
}